---
category: blog
by: Ólafur Páll Geirsson
title: "What's happening with macros?"
---

In September, we posted a
["Roadmap towards non-experimental macros"](http://www.scala-lang.org/blog/2017/10/09/scalamacros.html).
It's been two months since then and I'd like to share an update on
what's been happening.

## A diverse ecosystem

When starting this project, we wanted to first get an idea of how macros are
used in the community.
Not surprisingly, we discovered that macros are used in a variety of ways.
Here are some popular use-cases we found

- **code generation**: to avoid writing boilerplate by hand, which is
  both error-prone and cumbersome. This is used by [Play JSON] and [Spark].
- **embedded DSLs**: to attach new semantics to existing language syntax.
  This includes a wide range of applications from database query
  libraries like [Quill], to hardware construction frameworks like [Chisel] and
  build tools like [sbt].
- **optimizations**: to avoid expensive runtime allocations and method calls.
  This includes libraries like [spire] and [log4s].
- **developer ergonomics**: to surface source context information like variable
  names, file names and line numbers. This includes libraries like 
  [ScalaTest] and [sourcecode].
- **improved type-safety**: to increase the static guarantees of your programs
  beyond what the Scala language can provide. This includes libraries like [Refined].

The current scala-reflect macro system has in fact done a phenomenal job
at accommodating these diverse use-cases under a unified API.
The Scala ecosystem is rich as it is thanks to this wide range of applications
that are enabled by scala-reflect macros.

To get a better feel for how common each use-case is,
we performed an analysis on a corpus of 20,906 source files containing ~3
million lines of code from the Scala compiler community build.
The corpus includes sources for a diverse set of libraries ranging from
Akka, Cats, Scalaz, Monocle, twitter/util, Spire, Scrooge, Blaze, Algebra, fastparse,
Scanamo as well as applications like ornicar/lila (<https://lichess.org>).
Our analysis tracks the number of call-sites to each def macro and groups them by
whether the call-site comes from test or main sources.
Here are the top results:

**Main sources**
```
       443: org.scalactic.source.Position.here()Lorg/scalactic/source/Position;.
       356: org.parboiled2.Parser#rule(Lorg/parboiled2/Rule;)Lorg/parboiled2/Rule;.
       334: spire.syntax.EqOps#`===`(Ljava/lang/Object;Lscala/Predef/$eq$colon$eq;)Z.
       311: spire.syntax.CforSyntax#cfor(Ljava/lang/Object;Lscala/Function1;Lscala/Function1;Lscala/Function1;)V.
       287: akka.parboiled2.Parser#rule(Lakka/parboiled2/Rule;)Lakka/parboiled2/Rule;.
       267: spire.syntax.MultiplicativeSemigroupOps#`*`(Ljava/lang/Object;)Ljava/lang/Object;.
       226: spire.syntax.AdditiveSemigroupOps#`+`(Ljava/lang/Object;)Ljava/lang/Object;.
       170: slick.util.MacroSupportInterpolation#b(Lscala/collection/Seq;)V.
       156: reactivemongo.bson.Macros.handler()Lreactivemongo/bson/BSONDocumentReader;.
       152: spire.syntax.CforSyntax#cforRange(Lscala/collection/immutable/Range;Lscala/Function1;)V.
       130: scala.reflect.api.Universe#reify(Ljava/lang/Object;)Lscala/reflect/api/Exprs/Expr;.
       123: scalaxy.debug.package.require(ZLjava/lang/String;)V.
       110: spire.syntax.MultiplicativeGroupOps#`/`(Ljava/lang/Object;)Ljava/lang/Object;.
       108: play.api.libs.json.Json.format()Lplay/api/libs/json/OFormat;.
       104: scala.StringContext#f(Lscala/collection/Seq;)Ljava/lang/String;.
       102: play.api.libs.json.Json.writes()Lplay/api/libs/json/Writes;.
        98: spire.syntax.AdditiveGroupOps#`unary_-`()Ljava/lang/Object;.
        78: spire.syntax.AdditiveGroupOps#`-`(Ljava/lang/Object;)Ljava/lang/Object;.
        71: play.api.libs.json.Json.reads()Lplay/api/libs/json/Reads;.
        71: spire.syntax.OrderOps#compare(Ljava/lang/Object;)I.
        59: spire.syntax.PartialOrderOps#`<=`(Ljava/lang/Object;)Z.
        57: spire.syntax.PartialOrderOps#`<`(Ljava/lang/Object;)Z.
        56: spire.syntax.ModuleOps#`*:`(Ljava/lang/Object;Lspire/algebra/Module;)Ljava/lang/Object;.
        51: spire.syntax.SemiringOps#pow(I)Ljava/lang/Object;.
        47: spire.syntax.NRootOps#sqrt()Ljava/lang/Object;.
        46: org.log4s.Logger#error(Ljava/lang/Throwable;Ljava/lang/String;)V.
        44: spire.syntax.SignedOps#sign()Lspire/algebra/Sign;.
        44: spire.syntax.EqOps#`=!=`(Ljava/lang/Object;Lscala/Predef/$eq$colon$eq;)Z.
        42: cats.syntax.EqOps#`===`(Ljava/lang/Object;)Z.
        37: spire.macros.Checked.checked(Ljava/lang/Object;)Ljava/lang/Object;.
        37: spire.syntax.PartialOrderOps#`>`(Ljava/lang/Object;)Z.
        34: spire.syntax.PartialOrderOps#`>=`(Ljava/lang/Object;)Z.
        33: spire.syntax.MultiplicativeGroupOps#reciprocal()Ljava/lang/Object;.
        32: spire.syntax.NRootOps#nroot(I)Ljava/lang/Object;.
        31: com.typesafe.scalalogging.Logger#info(Ljava/lang/String;)V.
        30: spire.syntax.SemigroupoidOps#`|+|?`(Ljava/lang/Object;)Ljava/lang/Object;.
        ... truncated
```

**Test sources**
```
      9499: org.scalatest.Assertions#assert(ZLorg/scalactic/Prettifier;Lorg/scalactic/source/Position;)Lorg/scalatest/compatible/Assertion;.
      7590: org.scalactic.source.Position.here()Lorg/scalactic/source/Position;.
      1822: minitest.api.Asserts#assertEquals(Ljava/lang/Object;Ljava/lang/Object;)V.
       733: utest.asserts.Asserts#assert(Lscala/collection/Seq;)V.
       521: minitest.api.Asserts#assert(Z)V.
       384: minitest.api.Asserts#assert(ZLjava/lang/String;)V.
       358: spire.syntax.EqOps#`===`(Ljava/lang/Object;Lscala/Predef/$eq$colon$eq;)Z.
       307: org.specs2.specification.create.S2StringContextCreation#specificationInStringContext#s2(Lscala/collection/Seq;)Lorg/specs2/specification/core/Fragments;.
       306: scodec.bits.package.HexStringSyntax#hex(Lscala/collection/Seq;)Lscodec/bits/ByteVector;.
       288: org.scalatest.Assertions#assert(ZLjava/lang/Object;Lorg/scalactic/Prettifier;Lorg/scalactic/source/Position;)Lorg/scalatest/compatible/Assertion;.
       286: org.parboiled2.Parser#rule(Lorg/parboiled2/Rule;)Lorg/parboiled2/Rule;.
       270: spire.syntax.Literals#r()Lspire/math/Rational;.
       206: records.Rec.applyDynamic(Ljava/lang/String;Lscala/collection/Seq;)Lrecords/Rec;.
       186: spire.syntax.Literals#b()B.
       115: scala.async.internal.AsyncId.async(Lscala/Function0;)Ljava/lang/Object;.
        91: utest.asserts.Asserts#intercept(Lscala/runtime/BoxedUnit;Lscala/reflect/ClassTag;)Ljava/lang/Object;.
        90: org.scalatest.Matchers#AnyShouldWrapper#shouldBe(Lorg/scalatest/words/ResultOfATypeInvocation;)Lorg/scalatest/compatible/Assertion;.
        74: minitest.api.Asserts#intercept(Lscala/Function0;)V.
        68: scala.async.Async.async(Lscala/Function0;Lscala/concurrent/ExecutionContext;)Lscala/concurrent/Future;.
        66: spire.syntax.Literals#h()S.
        65: slick.collection.heterogeneous.HList#apply(I)Ljava/lang/Object;.
        63: org.specs2.specification.create.AutoExamples#eg(Lscala/Function0;Lorg/specs2/execute/AsResult;)Lorg/specs2/specification/core/Fragments;.
        55: scala.StringContext#f(Lscala/collection/Seq;)Ljava/lang/String;.
        53: org.scalatest.Matchers#StringShouldWrapper#shouldNot(Lorg/scalatest/words/CompileWord;Lorg/scalactic/source/Position;)Lorg/scalatest/compatible/Assertion;.
        46: com.twitter.scalding.serialization.macros.LowerPriorityImplicit#primitiveOrderedBufferSupplier()Lcom/twitter/scalding/serialization/OrderedSerialization;.
        42: spire.macros.Checked.checked(Ljava/lang/Object;)Ljava/lang/Object;.
        37: records.Rec.fld(Lrecords/Rec;)Ljava/lang/Object;.
        36: play.api.libs.json.Json.format()Lplay/api/libs/json/OFormat;.
        36: utest.asserts.Asserts#compileError(Ljava/lang/String;)Lutest/CompileError;.
        34: monix.execution.schedulers.ExecuteExtensions#executeAsync(Lscala/Function0;)V.
        34: spire.syntax.CforSyntax#cfor(Ljava/lang/Object;Lscala/Function1;Lscala/Function1;Lscala/Function1;)V.
        34: spire.util.Pack.longToByte(JI)B.
        33: scodec.bits.package.BinStringSyntax#bin(Lscala/collection/Seq;)Lscodec/bits/BitVector;.
        32: monix.execution.schedulers.ExecuteExtensions#executeTrampolined(Lscala/Function0;)V.
        ... truncated
```
The complete list of results can be seen in [this gist](https://gist.github.com/olafurpg/be9d01afab4e2e54e51be620279507aa).
Judging by the numbers, it seems that

- developer ergonomics macros such as `assert` and `source.Position` are
  heavily used in test sources, an order of magnitude more than any other
  category of macros.
  This is not surprising since large test suites contain many `assert` calls.
  Note that we excluded the ScalaTest sources from the corpus since they heavily biased
  the results by adding 140,000 call-sites to `scalactic.source.Position.here()`.
- Other popular uses of macros include optimization macros like those in spire/parboiled
  and code generation macros like Play JSON.
- there are not many usages of embedded DSLs in this corpus.

One caveat with this analysis is that the results are heavily biased by the
choice of the corpus, which is predominantly open source libraries.
Please get in touch with me if you would like to contribute more data to this corpus.
My contact info is at the end of this post.
We are especially interested in applications codebases rather than libraries,
and also embedded DSLs.

If there is interest, I'm happy to write a guide on how to run the analysis on
closed-source projects.
It's quite easy to do, and the results are anonymous excluding the signature
names of the invoked def macros, which can be manually obfuscated.
A large and representative corpus of "real-world" Scala codebases will help us
continue to use a data-driven approach to prioritize the development of new
macros.

## Tree transformations are tricky

Each of the diverse macro applications listed above require different sets of
features from the macro system.
For example, code generation macros typically only require inspection on existing types
and creation of new terms.
Embedded DSLs on the other hand typically require inspection and transformation of
existing terms created by the compiler.
Optimization macros like those in log4s may even be avoided with improvements
to alternative language features like `inline`.

Some features of the macro system appear to be relatively simple to support
across different compilers.
In the [scalacenter/macros] repository, we have a prototype macro system
that runs on both Scala 2.x and Dotty.
In only a few days, we got some interesting macros working for both compilers:
a JSON automatic serializer for case classes and most of the [sourcecode] macros.
That pretty exciting news for code generation macros and a subset of developer ergonomics macros.
Inspection on types and creation of new terms doesn't appear to introduce deep
technical road-blockers!
However, we struggled to implement some other macros like [utest] assert since
it requires the ability to transform trees.

Macros that transform trees produced by the compiler are demanding on the macro
system.
When a term is transformed, the macro library or the macro system must ensure
that internal invariants imposed by the compiler are respected.
For example, the Scala compiler assumes that typed tree nodes cannot have
untyped children.
In scala-reflect, the burden is on the macro author to ensure this invariant
holds.
Mistakes from mixing untyped and typed tree nodes result in cryptic compiler
crashes.
In the new macro system, we want to avoid exposing such bad experience to macro
authors and library users.

This observation that tree transformation are difficult to support doesn't
imply that new macros won't support them.
It simply means that we need give this problem more time and thought so that we
can come up with a robust solution.
So far, we have seen two promising ideas to address or circumvent this problem,
one by Martin Odersky and one by Lionel Parreaux.

## Unification of LMS and Macros

Martin Odersky recently shared [a gist](https://gist.github.com/odersky/f91362f6d9c58cc1db53f3f443311140)
on Principled Metaprogramming for Scala.
The design proposed in this gist is quite close to Meta OCaml as well as to a
calculus by Davies and Pfenning inspired by modal logic, see
["A modal analysis of staged computation"](https://dl.acm.org/citation.cfm?doid=382780.382785).

This proposal has triggered a rich discussion in the gist, which you may find interesting.
However, the proposal may go too far from current scala-reflect macros to
cause a migration concern.
Quoting Martin Odersky from
[r/scala](https://www.reddit.com/r/scala/comments/7emo4s/oderskys_ideas_about_a_new_design_for_macros_that/dq6m1da/)

> One attractive aspect of the system is that it works equally well for staging
> and for macros.  But as a macro system it is quite restrictive because it
> imposes a strong typing discipline, only works for full expressions, and in
> its original version does not allow for code inspection. Lionel's Parreaux's
> Squid system (paper to appear at upcoming POPL) is more powerful in that it
> does allow inspection.

Lionel Parreaux ([@LPTK]) is a PhD student at EPFL who has been working on
related problems for the past couple years as part of his research on the
intersection of database systems, programming languages and large-scala data
analysis.

## Squid: reusable and type-safe quasiquotes

[Squid] is a metaprogramming framework that facilitates the type-safe
manipulation of Scala programs through quasiquotes.
Unlike scala-reflect quasiquotes, Squid quasiquotes are statically guaranteed
to be well-typed, well-scoped and hygienic.
The properties of Squid quasiquotes make them ideal for robust and safe
transformation of trees, the exact problem we struggled with in our prototype
macro system.

One important attribute of Squid quasiquotes is that they are reusable.
Similar to scala-reflect quasiquotes, it's possible to write generic utility
functions with Squid quasiquotes and compose them into more complex tree
structures.
Many alternative statically typed quasiquote systems do not support this
ability to combine small quasiquote fragments into larger programs.
This functionality is enabled by Squid's first-class encoding of free
variables.

Squid quasiquotes statically track the context/scope of a quasiquote in its type to
prevent references to unbound identifiers.
For example, `code"(x: Int) + 1"` would be rejected since `x` is undefined.
Instead, quasiquotes must explicitly annotate free variables
using question marks `code"(?x: Int) + 1)`.
Free variables are then tracked in the second parameter of quasiquote's type
`Code[Int, {x: Int}]`.

To learn more about Squid works, I highly recommend reading their upcoming POPL
2018 paper
["Unifying Analytic and Statically-Typed Quasiquotes"](https://infoscience.epfl.ch/record/232427).
Here is just one interesting table from the paper that I want to include here

![Squid quasiquotes]({{ site.baseurl }}/resources/img/squid-quasiquotes.png)

There are still many open questions on how to incorporate Squid with the new macros.
For example,

- Squid quasiquotes eagerly convert compiler trees to Squid's IR. This may
  introduce problems for Scala syntax like patterns and important
  metadata may get lost like positions/attachments.
- Squid currently does not support the ability to define methods or classes in
  quasiquotes.

I believe these problems are solvable, and we are discussing with
Lionel and colleagues from and his lab about potential collaboration.
If successful, the new Scala macros may have potential to push the
state-of-the-art in metaprogramming.

## Conclusion

There remain many open challenges in the design of the new macros.
I believe there is a lot for us to learn from related research in this field.
Our next step is to continue the work in the [scalacenter/macros] repository,
which implements the building blocks that are required to support higher-level
frameworks such as Squid.
These building blocks include:
- a rich compile-time reflection API to query for properties of types, symbols
  and trees.
- a standard syntax to declare and implement def macros, which will be similar
  but distinct from the syntax to define scala-reflect def macros.

If you are interested to join the effort, don't hesitate to get in touch!
You can reach me via email (olafurpg@gmail.com) or [@olafurpg] on Twitter.

[Play JSON]: https://www.playframework.com/documentation/2.6.x/ScalaJsonAutomated
[Circe]: https://circe.github.io/circe/
[Quill]: http://getquill.io/
[Chisel]: https://chisel.eecs.berkeley.edu/
[sbt]: http://www.scala-sbt.org/1.x/docs/Scope-Delegation.html
[log4s]: https://github.com/Log4s/log4s
[spire]: https://github.com/non/spire/
[spire]: https://github.com/non/spire/
[ScalaTest]: http://www.scalatest.org/
[sourcecode]: https://github.com/lihaoyi/sourcecode
[Refined]: https://github.com/fthomas/refined
[Spark]: https://spark.apache.org/sql/
[scalacenter/macros]: https://github.com/scalacenter/macros
[utest]: https://github.com/lihaoyi/utest
[Squid]: https://github.com/epfldata/squid/
[@LPTK]: https://github.com/lptk
[@olafurpg]: https://twitter.com/olafurpg
